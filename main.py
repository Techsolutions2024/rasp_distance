import cv2
import time
import threading
import numpy as np
from ultralytics import YOLO
from collections import deque
import queue

class LightweightDetectionPipeline:
    def __init__(self, model_path="best_int8_openvino_model/", camera_id=1):
        # C·∫•u h√¨nh t·ªëi ∆∞u
        self.RESOLUTION = (416, 320)
        self.DISPLAY_RESOLUTION = (640, 480)
        self.SKIP_FRAMES = 4  # TƒÉng skip ƒë·ªÉ gi·∫£m t·∫£i
        self.BUFFER_SIZE = 1  # Gi·∫£m buffer ƒë·ªÉ gi·∫£m latency
        self.ALPHA = 0.8
        
        # Kh·ªüi t·∫°o camera calibration
        self._init_camera_calibration()
        
        # Kh·ªüi t·∫°o YOLO model
        self._init_yolo_model(model_path)
        
        # Lightweight queues
        self.frame_queue = queue.Queue(maxsize=1)
        self.detection_queue = queue.Queue(maxsize=1)
        
        # Control flags
        self.running = True
        
        # LIGHTWEIGHT FPS tracking - ch·ªâ track c√°i c·∫ßn thi·∫øt
        self.fps_counter = 0
        self.fps_start_time = time.time()
        self.current_fps = 0
        self.last_fps_update = 0
        
        # Detection timing (ch·ªâ track inference time)
        self.last_inference_time = 0
        self.detection_fps = 0
        
        # Pre-allocated buffers
        self.processing_buffer = np.zeros((*self.RESOLUTION[::-1], 3), dtype=np.uint8)
        
        self.camera_id = camera_id
        
    def _init_camera_calibration(self):
        """Kh·ªüi t·∫°o camera calibration - t·ªëi ∆∞u h√≥a"""
        try:
            data = np.load("camera_calib.npz")
            self.mtx = data["camera_matrix"]
            self.dist = data["dist_coeffs"]
            
            # Ch·ªâ t·∫°o map cho detection resolution (kh√¥ng c·∫ßn display resolution)
            self.newcameramtx, self.roi = cv2.getOptimalNewCameraMatrix(
                self.mtx, self.dist, self.RESOLUTION, 0.3, self.RESOLUTION  # alpha=0.3 thay v√¨ 0
            )
            self.map1, self.map2 = cv2.initUndistortRectifyMap(
                self.mtx, self.dist, None, self.newcameramtx, 
                self.RESOLUTION, cv2.CV_16SC2
            )
            
            # T√≠nh focal length
            f_x = self.newcameramtx[0, 0]
            f_y = self.newcameramtx[1, 1]
            self.focal_length = (f_x + f_y) / 2
            
            self.use_calibration = True
            print(f"‚úì Camera calibration loaded")
            
        except Exception as e:
            print(f"‚ö† Using default calibration: {e}")
            self.use_calibration = False
            self.focal_length = 350
            self.roi = (0, 0, self.RESOLUTION[0], self.RESOLUTION[1])
    
    def _init_yolo_model(self, model_path):
        """Kh·ªüi t·∫°o YOLO model v·ªõi c·∫•u h√¨nh si√™u t·ªëi ∆∞u"""
        print("üîÑ Loading YOLO model...")
        self.model = YOLO(model_path)
        
        # C·∫•u h√¨nh si√™u t·ªëi ∆∞u cho Pi 4
        self.model.overrides.update({
            'verbose': False,
            'conf': 0.6,      # TƒÉng confidence ƒë·ªÉ gi·∫£m post-processing
            'iou': 0.8,       # TƒÉng IoU ƒë·ªÉ gi·∫£m NMS
            'max_det': 15,    # Gi·∫£m max detection
            'device': 'cpu',
            'half': False,
            'agnostic_nms': False,  # T·∫Øt agnostic NMS
            'retina_masks': False,  # T·∫Øt retina masks
        })
        
        # Simplified real heights
        self.REAL_HEIGHTS = {
            0: 1.6, 1: 1.6, 2: 4.0, 3: 3.2, 4: 1.1,
            5: 4.2, 6: 3.2, 7: 1.5, 8: 1.5, 9: 3.0
        }
        
        print("‚úì YOLO model loaded")
    
    def camera_thread(self):
        """Thread ƒë·ªçc camera - ƒë∆°n gi·∫£n h√≥a t·ªëi ƒëa"""
        cap = cv2.VideoCapture(self.camera_id, cv2.CAP_DSHOW)
        
        # C·∫•u h√¨nh camera t·ªëi ∆∞u
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.DISPLAY_RESOLUTION[0])
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.DISPLAY_RESOLUTION[1])
        cap.set(cv2.CAP_PROP_FPS, 30)
        cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        if not cap.isOpened():
            print("‚ùå Cannot open camera")
            self.running = False
            return
        
        print(f"‚úì Camera ready")
        
        while self.running:
            ret, frame = cap.read()
            if not ret:
                continue
            
            # Resize ngay khi ƒë·ªçc ƒë·ªÉ gi·∫£m memory
            frame_small = cv2.resize(frame, self.RESOLUTION)
            
            # Ch·ªâ put frame n·∫øu queue tr·ªëng (drop old frames)
            if self.frame_queue.empty():
                try:
                    self.frame_queue.put_nowait(frame_small)
                except queue.Full:
                    pass
        
        cap.release()
        print("üì∑ Camera stopped")
    
    def detection_thread(self):
        """Thread detection - t·ªëi ∆∞u h√≥a t·ªëi ƒëa"""
        frame_counter = 0
        
        while self.running:
            try:
                # L·∫•y frame (timeout ng·∫Øn)
                frame = self.frame_queue.get(timeout=0.05)
                frame_counter += 1
                
                # Skip frames ƒë·ªÉ gi·∫£m t·∫£i
                if frame_counter % self.SKIP_FRAMES != 0:
                    continue
                
                # Undistort n·∫øu c·∫ßn (ch·ªâ cho detection)
                if self.use_calibration:
                    cv2.remap(frame, self.map1, self.map2, 
                             cv2.INTER_LINEAR, self.processing_buffer)
                    x, y, w, h = self.roi
                    detection_frame = self.processing_buffer[y:y+h, x:x+w]
                else:
                    detection_frame = frame
                
                # YOLO inference
                start_time = time.time()
                results = self.model(detection_frame, verbose=False)[0]
                self.last_inference_time = time.time() - start_time
                
                # T√≠nh detection FPS ƒë∆°n gi·∫£n
                if self.last_inference_time > 0:
                    self.detection_fps = 1.0 / self.last_inference_time
                
                # X·ª≠ l√Ω k·∫øt qu·∫£ nhanh
                detections = self._process_detections_fast(results)
                
                # Resize frame v·ªÅ display size ƒë·ªÉ hi·ªÉn th·ªã
                display_frame = cv2.resize(frame, self.DISPLAY_RESOLUTION)
                
                # G·ª≠i k·∫øt qu·∫£ (non-blocking)
                detection_data = {
                    'frame': display_frame,
                    'detections': detections,
                    'timestamp': time.time()
                }
                
                # Drop old detection n·∫øu queue ƒë·∫ßy
                if not self.detection_queue.empty():
                    try:
                        self.detection_queue.get_nowait()
                    except queue.Empty:
                        pass
                
                try:
                    self.detection_queue.put_nowait(detection_data)
                except queue.Full:
                    pass
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"Detection error: {e}")
                continue
        
        print("üéØ Detection stopped")
    
    def _process_detections_fast(self, results):
        """X·ª≠ l√Ω detection nhanh - t·ªëi ∆∞u h√≥a"""
        detections = []
        
        if results.boxes is None or len(results.boxes) == 0:
            return detections
        
        # Scale factor t·ª´ detection v·ªÅ display
        scale_x = self.DISPLAY_RESOLUTION[0] / self.RESOLUTION[0]
        scale_y = self.DISPLAY_RESOLUTION[1] / self.RESOLUTION[1]
        
        # Ch·ªâ l·∫•y top detections
        boxes = results.boxes[:10]  # Gi·ªõi h·∫°n ƒë·ªÉ tƒÉng t·ªëc
        
        for box in boxes:
            cls_id = int(box.cls[0].item())
            conf = float(box.conf[0].item())
            
            if conf < 0.5:  # Skip low confidence
                continue
            
            # Scale coordinates
            x1, y1, x2, y2 = box.xyxy[0].tolist()
            x1, x2 = int(x1 * scale_x), int(x2 * scale_x)
            y1, y2 = int(y1 * scale_y), int(y2 * scale_y)
            
            # T√≠nh kho·∫£ng c√°ch nhanh
            distance = None
            if cls_id in self.REAL_HEIGHTS:
                pixel_height = y2 - y1
                if pixel_height > 15:  # TƒÉng threshold
                    real_height = self.REAL_HEIGHTS[cls_id]
                    distance = self.ALPHA * (real_height * self.focal_length) / pixel_height
            
            detections.append({
                'bbox': (x1, y1, x2, y2),
                'class_id': cls_id,
                'confidence': conf,
                'label': self.model.names[cls_id],
                'distance': distance
            })
        
        return detections
    
    def display_thread(self):
        """Thread hi·ªÉn th·ªã - t·ªëi ∆∞u FPS tracking"""
        last_frame = None
        
        while self.running:
            try:
                # L·∫•y detection data
                detection_data = self.detection_queue.get(timeout=0.1)
                
                frame = detection_data['frame']
                detections = detection_data['detections']
                
                # V·∫Ω detections
                annotated_frame = self._draw_detections_fast(frame, detections)
                
                # LIGHTWEIGHT FPS tracking - ch·ªâ t√≠nh t·ªïng FPS
                self.fps_counter += 1
                current_time = time.time()
                
                # C·∫≠p nh·∫≠t FPS m·ªói gi√¢y (thay v√¨ m·ªói frame)
                if current_time - self.fps_start_time >= 1.0:
                    self.current_fps = self.fps_counter / (current_time - self.fps_start_time)
                    self.fps_counter = 0
                    self.fps_start_time = current_time
                    self.last_fps_update = current_time
                
                # V·∫Ω FPS info (ƒë∆°n gi·∫£n)
                self._draw_simple_fps(annotated_frame, current_time)
                
                # Hi·ªÉn th·ªã
                cv2.imshow("YOLO Detection", annotated_frame)
                last_frame = annotated_frame
                
            except queue.Empty:
                # Hi·ªÉn th·ªã frame c≈© n·∫øu kh√¥ng c√≥ detection m·ªõi
                if last_frame is not None:
                    cv2.imshow("YOLO Detection", last_frame)
                continue
            
            # Check quit
            if cv2.waitKey(1) & 0xFF == ord('q'):
                self.running = False
                break
        
        cv2.destroyAllWindows()
        print("üñ•Ô∏è Display stopped")
    
    def _draw_detections_fast(self, frame, detections):
        """V·∫Ω detections nhanh"""
        annotated_frame = frame.copy()
        
        for det in detections[:8]:  # Gi·ªõi h·∫°n s·ªë detections ƒë·ªÉ v·∫Ω
            x1, y1, x2, y2 = det['bbox']
            label = det['label']
            distance = det['distance']
            
            # V·∫Ω bbox
            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # Label ƒë∆°n gi·∫£n
            if distance is not None:
                text = f"{label} {distance:.1f}m"
            else:
                text = label
            
            cv2.putText(annotated_frame, text, (x1, y1 - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
        
        return annotated_frame
    
    def _draw_simple_fps(self, frame, current_time):
        """V·∫Ω FPS info ƒë∆°n gi·∫£n - ch·ªâ hi·ªÉn th·ªã khi c√≥ update"""
        # Ch·ªâ v·∫Ω FPS n·∫øu c√≥ update g·∫ßn ƒë√¢y (trong 2 gi√¢y)
        if current_time - self.last_fps_update < 2.0:
            cv2.putText(frame, f"FPS: {self.current_fps:.1f}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            
            # Hi·ªÉn th·ªã detection FPS n·∫øu c√≥
            if self.detection_fps > 0:
                cv2.putText(frame, f"Det: {self.detection_fps:.1f}", (10, 60),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
    
    def run(self):
        """Ch·∫°y pipeline t·ªëi ∆∞u"""
        print("üöÄ Starting lightweight pipeline...")
        
        # Kh·ªüi ƒë·ªông threads
        threads = [
            threading.Thread(target=self.camera_thread, name="Camera"),
            threading.Thread(target=self.detection_thread, name="Detection"),
            threading.Thread(target=self.display_thread, name="Display")
        ]
        
        for thread in threads:
            thread.daemon = True
            thread.start()
        
        try:
            threads[2].join()  # Ch·ªù display thread
        except KeyboardInterrupt:
            print("\n‚èπÔ∏è Stopping...")
            self.running = False
        
        # Cleanup
        for thread in threads[:-1]:
            thread.join(timeout=0.5)
        
        print("‚úÖ Pipeline stopped")

# S·ª≠ d·ª•ng
if __name__ == "__main__":
    pipeline = LightweightDetectionPipeline(
        model_path="best_int8_openvino_model/",
        camera_id=1
    )
    pipeline.run()
